<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">

        <!-- <link rel="shortcut icon" type="image/x-icon" href="images/cv.ico"> -->
        <title>Jae-Sung Bae</title>

        <!-- style -->
        <link rel="stylesheet" type="text/css" href="style.css">

        <!-- Latest compiled and minified CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
        <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous"> -->
        <!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous"> -->
    </head>
    <body>
    <div class="continaer page-wrapper">
    <!-- <div class="row"> -->
        <div class="container">
            <h1>Jae-Sung Bae</h1>
            <p>bjsd3 [at] alumni [dot] kaist [dot] ac [dot] kr</p>
            <!--- <p class="lead">undergrad studying cs and math<br> </p> -->
        </div>
    <div class="container page-wrapper">
        <ul>
        <!-- <li><a href="index.html">Home</a></li>  -->
        <li> <a href="data/CV_jaesung_bae_231024.pdf">CV</a></li> 
        <li> <a href="https://scholar.google.co.kr/citations?user=ay1zanAAAAAJ&hl=ko">Google Scholar</a></li>
        <li> <a href="http://www.linkedin.com/in/jaesung-bae-955410157">LinkedIn</a> </li>
        <li> <a href="#projects">Projects</a></li>
        <li> <a href="#publications">Publications</a></li>
        <li> <a href="#invited_talks">Invited Talks</a></li>
        <!-- <li> <a href="https://github.com/czlwang">Github</a></li> 
        <li><a href="art/index.html">Drawing</a></li> 
        <li><a href="zettel/index.html">Zettelkasten</a></li> 
        <li><a href="misc/index.html">Misc</a></li>  -->
        </ul>
    </div>

    <div class="container">
        <h2>About</h2>
        <hr>
        <div class="row">
            <div class="col-md-7">
                <p>
                    I am presently working for <a href="https://research.samsung.com/">Samsung Research</a> as a speech AI researcher. 
                    My main research topic has recently been personalized and zero-shot on-device TTS systems. 
                    Previously, I worked at <a href="https://kr.ncsoft.com/en/index.do">NCSOFT</a>, a game company, mainly 
                    studying expressive TTS and prosody controllable TTS systems. 
                    My academic background includes a BS in Electrical and Electronic Engineering from <a href="https://www.yonsei.ac.kr/en_sc/">Yonsei University</a> 
                    and I earned my master's degree in Electrical Engineering from <a href="https://www.kaist.ac.kr/en/">KAIST 
                    </a> in <a href="http://brain.kaist.ac.kr/brain/main.php">BREIL lab</a> advised by Daeshik Kim. 
                    I am interested in speech synthesis and speech representation learing of prosody and spaeker identity. 
                    Currently, I am widening my interest to combining speech synthesis with techniques from various fields, 
                    such as spontaneous speech-to-speech, multimodal generation, video dubbing, etc.
                </p>
                <p>
                    &nbsp&nbsp Below shows my <a href="#projects">projects</a>, <a href="#publications">publications</a>, and <a href="#invited_talks">invited talks</a>. Please refere to my <a href="data/CV_jaesung_bae_231024.pdf"><strong>CV</strong></a> for further details.
                </p>
            </div>
            <div class="col-md-4">
                <img src="images/profile.jpg" class="img-circle" width="275px" height="275px">
            </div>
        </div>
    </div>

    <div class="container" id="projects">
        <h2>Projects</h2>
        <hr>
        <div class="row">
            <div class="col-md-9">
                <p>
                You can click each project and check demos and further information.
                </p>
            </div>
            <div class="col-md-3 col-md-offset-3">
            <p><a class="btn btn-default" href="" role="button">Go to top</a></p>
            </div>
        </div>
        <div class="row">
            <div class="col-md-3" OnClick="location.href='projects/baseball.html'" style="cursor:pointer" id="project:baseball">
                <video class="main_project_img" width="240" height="160" autoplay loop>
                    <source src="images/baseball_example_png.mp4" type="video/mp4" width="240px" height="160px">
                    Your browser does not support the video tag.
                </video>
            </div>
            <div class="col-md-8" OnClick="location.href='projects/baseball.html'" style="cursor:pointer" id="project:baseball">
                <h3>TTS System in Baseball Broadcast Scenario<br><small>Mar 2019 - Mar 2021 (@NCSOFT)</small></h3>
                <p>
                I researched and developed an expressive TTS system that can generate speech with dynamic expressions suitable for diverse baseball situations. I published several demos on NCSOFT’s official blog and news articles.
                <b>Kindly recommand to click this project, and see the demo videos.</b>
                <!-- I researched and developed an expressive TTS system that can generate speech with dynamic expressions that are suitable for different baseball situations.
                It can generate speech with 4 emotions (highly expressive, expressive, neutral, and depressed).
                It can generate expressive speech responses to the input text symbols (,, ~, !, ?).
                Published several demos on NCSOFT’s official blog and news articles. Demo and article link: https://blog.ncsoft.com/prosody-control-ai-20201210/ -->
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-3" OnClick="location.href='projects/uninverse.html'" style="cursor:pointer" id="project:universe">
                <img class="main_project_img" src="images/universe_1.jpg" width="240px" height="160px">
            </div>
            <div class="col-md-8" OnClick="location.href='projects/uninverse.html'" style="cursor:pointer" id="project:universe">
                <h3>TTS System of K-pop Fandom Platform, “UNIVERSE” (live service)<br><small>Mar 2019 - Apr 2022 (@NCSOFT)</small></h3>
                <p>
                I contributed to the research and development of a multi-speaker TTS system replicating the voices of numerous K-pop artists, approximately 100 in total, within a single TTS system.
                This TTS system was used in "UNIVERSE" service, which is a K-pop fan community platform.
                <!-- I contributed to research and develop a multi-speaker TTS system that can generate various K-pop artists' voices (about 100 artists) in a single TTS system. The TTS system was used in Universe, which is a K-pop fan community platform. <br> -->
                </p>
            </div>
        </div>
        
        <div class="row">
            <div class="col-md-3" OnClick="location.href='projects/controllable.html'" style="cursor:pointer" id="project:universe">
                <img class="main_project_img" src="images/thumbnail_controllable.jpg" width="240px" height="100px">
            </div>
            <div class="col-md-8" OnClick="location.href='projects/controllable.html'" style="cursor:pointer" id="project:controllable">
                <h3>Fine-grained Prosody Control of TTS System (prototype web service)<br><small>Mar 2021 - Apr 2022 (@NCSOFT)</small></h3>
                <p>
                    I conducted research and developed a TTS system that is capable of controlling the prosody of speech in a fine-grained level.
                    With this system, users were able to modify the speech to have desired prosody.
                     <!-- so that the users can generate speech with the prosody they want.  -->
                    This system is released as an in-company web service and was widely used to make an guide videos of NCSOFT's game.

                    <!-- I contributed to releasing this fine-grained controllable TTS system as a prototype web service which is opened as an in-company service. 
                    For example, the speech generated with the fine-grained controllable TTS system was used in the video introducing the updated patch note of the game (Trickster-M).
                    Youtube link: https://www.youtube.com/watch?v=_Ssb9y73XtI -->
                </p>
            </div>
        </div>
    </div>
    <br>

    <div class="container" id="publications">
        <h2>Publications</h2>
        <hr>
        <div class="row">
            <div class="col-md-9">
                <h5>
                *: Equal Contribution
                </h5>
            </div>
            <div class="col-md-3 col-md-offset-3">
            <p><a class="btn btn-default" href="" role="button">Go to top</a></p>
            </div>
        </div>
        <!-- <a href=""> </a><br> -->
        <!-- </p> -->
        <div class="row">
            <div class="col-md-10 pub-year">
                2023
            </div>
        </div>
        <div class="row">
            <div class="col-md-10">
                <h4>
                Latent Filling: Latent Space Data Augmentation for Zero-shot Speech Synthesis
                <span class="h5"><br>
                <b>Jae-Sung Bae</b>, Joun Yeop Lee, Ji-Hyun Lee, Seongkyu Mun, Taehwa Kang, Hoon-Young Cho, Chanwoo Kim<br>
                <i>arXiv preprint arXiv: 2310.03538,</i> 2023. (Submitted to ICASSP 2024)<br>
                <a href="https://arxiv.org/abs/2310.03538">[paper]</a>
                <a href="https://srtts.github.io/latent-filling/index.html">[demo]</a>
                </span>
                </h4>
            </div>
        </div>
        <div class="row">
            <div class="col-md-10">
                <h4>
                MELS-TTS : Multi-Emotion Multi-Lingual Multi-Speaker Text-to-Speech System via Disentangled Style Tokens
                <span class="h5"><br>
                Heejin Choi, <b>Jae-Sung Bae</b>, Joun Yeop Lee, Seongkyu Mun, Jihwan Lee, Hoon-Young Cho, Chanwoo Kim<br>
                (Submitted to ICASSP 2024)<br>
                </span>
                </h4>
            </div>
        </div>
        <div class="row">
            <div class="col-md-10">
                <h4>
                Hierarchical Timbre-Cadence Speaker Encoder for Zero-shot Speech Synthesis
                <span class="h5"><br>
                Joun Yeop Lee, <b>Jae-Sung Bae</b>, Seongkyu Mun, Jihwan Lee, Ji-Hyun Lee, Hoon-Young Cho, Chanwoo Kim<br>
                In<i> Proc. INTERSPEECH</i>, 2023. <br>
                <a href="https://www.isca-speech.org/archive/interspeech_2023/lee23f_interspeech.html">[paper]</a>
                <a href="https://srtts.github.io/tc-zstts/">[demo]</a>
                </span>
                </h4>
            </div>
        </div>
        <div class="row">
            <div class="col-md-10">
                <h4>
                Avocodo: Generative Adversarial Network for Artifact-free Vocoder
                <span class="h5"><br>
                Taejun Bak, Junmo Lee, Hanbin Bae, Jinhyeok Yang, <b>Jae-Sung Bae</b>, Young-Sun Joo<br>
                In<i> Proc. AAAI</i>, 2023.<br>
                </small>
                <a href="https://arxiv.org/abs/2206.13404">[paper]</a>
                <a href="https://nc-ai.github.io/speech/publications/Avocodo/index.html">[demo]</a>
                <a href="https://github.com/ncsoft/avocodo">[code]</a>
                </h4>
            </div>
        </div>
        <br>
        <!-- <hr> -->
        <div class="row">
            <div class="col-md-10 pub-year">
                2022
            </div>
        </div>
        <div class="row">
            <div class="col-md-12">
                <h4>
                Hierarchical and Multi-Scale Variational Autoencoder for Diverse and Natural Non-Autoregressive Text-to-Speech
                <span class="h5"><br>
                <b>Jae-Sung Bae</b>, Jinhyeok Yang, Tae-Jun Bak, Young-Sun Joo<br>
                In <i>Proc. INTERSPEECH</i>, 2022.<br>
                <a href="https://arxiv.org/abs/2204.04004">[paper]</a>
                <a href="https://nc-ai.github.io/speech/publications/himuv-tts/">[demo]</a>
                <a href="https://youtu.be/3U5cEu0gFYY ">[video]</a>
                </span>
                </h4>
            </div>
        </div>
        <div class="row">
            <div class="col-md-10">
                <h4>
                Into-TTS : Intonation Template Based Prosody Control System
                <span class="h5"><br>
                Jihwan Lee, Joun Yeop Lee, Heejin Choi, Seongkyu Mun, Sangjun Park, <b>Jae-Sung Bae</b>, Chanwoo Kim<br>
                <i>arXiv preprint arXiv:2204.01271,</i> 2022.<br>
                <a href="https://arxiv.org/abs/2204.01271">[paper]</a>
                <a href="https://srtts.github.io/IntoTTS/">[demo]</a>
                </span>
                </h4>
            </div>
        </div>
        <br>
        <!-- <hr> -->
        <div class="row">
            <div class="col-md-10 pub-year">
                2021
            </div>
        </div>
        <div class="row">
            <div class="col-md-10">
                <h4>
                Hierarchical Context-Aware Transformers for Non-Autoregressive Text to Speech
                <span class="h5"><br>
                <b>Jae-Sung Bae</b>, Tae-Jun Bak, Young-Sun Joo, and Hoon-Young Cho
                <br>In <i>Proc. INTERSPEECH</i>, 2021.<br>
                <a href="https://arxiv.org/abs/2106.15144">[paper]</a>
                <a href="https://nc-ai.github.io/speech/publications/hierarchical-transformers-tts/">[demo]</a>
                </h4>
            </div>
        </div>

        <div class="row">
            <div class="col-md-10">
                <h4>
                GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis
                <span class="h5"><br>
                Jinhyeok Yang*, <b>Jae-Sung Bae*</b>, Taejun Bak, Youngik Kim, and Hoon-Young Cho<br>
                In <i>Proc. INTERSPEECH</i>, 2021.<br>
                <a href="https://arxiv.org/abs/2106.15153">[paper]</a>
                <a href="https://nc-ai.github.io/speech/publications/ganspeech/">[demo]</a>
                </h4>
                <h5>
                </h5>
            </div>
        </div>

        <div class="row">
            <div class="col-md-10">
                <h4>
                FastPitchFormant: Source-filter based Decomposed Modeling for Speech Synthesis
                <span class="h5"><br>
                Taejun Bak, <b>Jae-Sung Bae</b>, Hanbin Bae, Young-Ik Kim, and Hoon-Young Cho<br>
                In <i>Proc. INTERSPEECH</i>, 2021.<br>
                <a href="https://arxiv.org/abs/2106.15123">[paper]</a>
                <a href="https://nc-ai.github.io/speech/publications/fastpitchformant/">[demo]</a>
                </h4>
            </div>
        </div>
        
        <div class="row">
            <div class="col-md-10">
                <h4>
                A Neural Text-to-Speech Model Utilizing Broadcast Data Mixed with Background Music
                <span class="h5"><br>
                Hanbin Bae, <b>Jae-Sung Bae</b>, Young-Sun Joo, Young-Ik Kim, and Hoon-Young Cho<br>
                In <i>Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</i>, 2021.<br>
                <a href="https://arxiv.org/abs/2103.03049">[paper]</a>
                <a href="https://nc-ai.github.io/speech/publications/tts-with-bgm-data/">[demo]</a>
                </h4>
                <h5>
                </h5>
            </div>
        </div>

        <br>
        <!-- <hr> -->

        <div class="row">
            <div class="col-md-10 pub-year">
                2020
            </div>
        </div>

        <div class="row">
            <div class="col-md-10">
                <h4>
                    Speaking Speed Control of End-to-End Speech Synthesis using Sentence-Level Conditioning
                <span class="h5"><br>
                <b>Jae-Sung Bae</b>, Hanbin Bae, Young-Sun Joo, Junmo Lee, Gyeong-Hoon Lee, Hoon-Young Cho<br>
                In <i>Proc. INTERSPEECH</i>, 2020.<br>
                <a href="https://arxiv.org/abs/2007.15281">[paper]</a>
                <a href="https://nc-ai.github.io/speech/publications/speed-controllable-tts/">[demo]</a>
                <a href="https://youtu.be/WyDfc53Ez_A ">[video]</a>
                </h4>
            </div>
        </div>

        <br>
        <!-- <hr> -->

        <div class="row">
            <div class="col-md-10 pub-year">
                2019
            </div>
        </div>

        <div class="row">
            <div class="col-md-10">
                <h4>
                    End-Point Detection with State Transition Model based on Chunk-Wise Classification 
                <span class="h5"><br>
                Juntae Kim*, <b>Jaesung Bae*</b>, Minsoo Hahn<br>
                <i>arXiv preprint arXiv:1912.10442,</i> 2019.<br>
                <a href="https://arxiv.org/abs/1912.10442">[paper]</a>
                </h4>
            </div>
        </div>

        <div class="row">
            <div class="col-md-10">
                <h4>
                Phase-Aware Speech Enhancement with a Recurrent Two Stage Network
                <span class="h5"><br>
                Juntae Kim, and <b>Jae-Sung Bae</b><br>
                <i>arXiv preprint arXiv:2001.09772</i> 2019.<br>
                <a href="https://arxiv.org/abs/2001.09772">[paper]</a>
                </h4>
                <h5>
                </h5>
            </div>
        </div>
        
        <!-- <hr> -->
        <br>

        <div class="row">
            <div class="col-md-10 pub-year">
                2018
            </div>
        </div>

        <div class="row">
            <div class="col-md-10">
                <h4>
                    End-to-End Speech Command Recognition with Capsule Network
                <span class="h5"><br>
                <b>Jae-Sung Bae</b>, Dae-Shik Kim<br>
                In <i>Proc. INTERSPEECH</i>, 2018.<br>
                <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2018/bae18_interspeech.pdf">[paper]</a>
                </h4>
            </div>
        </div>
    </div>
    <br>

    <div class="container" id="invited_talks">
        <h2>Invited Talks</h2>
        <hr>
        <div class="row">
            <div class="col-md-9">
                <h4>
                <a href="https://youtu.be/iFtZqjedoWE">End-to-End Speech Command Recognition with Capsule Network</a>
                <br>
                <span class="h5"><b>NAVER Corp.,</b> Seong-Nam, Republic of Korea</span>
                <br>
                <small>Sep 2018</small>
                </h4>
            </div>
            <div class="col-md-1 col-md-offset-1">
            <p><a class="btn btn-default" href="" role="button">Go to top</a></p>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
    </div> <!--   page-wrapper  -->
    </body>
</html>
